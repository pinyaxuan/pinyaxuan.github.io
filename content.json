[{"title":"【科赛-练习赛】：文本情感分类模型搭建","date":"2019-03-15T09:36:15.000Z","path":"2019/03/15/kesci-sentiment-classification/","text":"记录参加科赛举办的文本情感分类模型-练习赛，比赛地址： 文本情感分类模型搭建 | 练习赛使用TFIDF提前词频特征，利用PyTorch搭建线性预测模型，预测结果AUC 0.8658，截止2019-3-14科赛网公网排名第三。 赛题描述本练习赛所用数据，是名为「Roman Urdu DataSet」的公开数据集。 这些数据，均为文本数据。原始数据的文本，对应三类情感标签：Positive, Negative, Netural。 本练习赛，移除了标签为Netural的数据样例。因此，练习赛中，所有数据样例的标签为Positive和Negative。 本练习赛的任务是「分类」。「分类目标」是用训练好的模型，对测试集中的文本情感进行预测，判断其情感为「Negative」或者「Positive」。 GitHubhttps://github.com/jianchengss/kesci-sentiment-classification.git 提交结果 实验结果摘要： Date SHA Method AUC-train AUC-kesci P R F 20190307 8225844 random - 0.5057 - - - 20190312 05a6790 rfc-1 0.8130 0.8054 0.7516 0.7542 0.7520 20190312 d4e00a1 neural_clf 0.8336 0.8357 0.7831 0.7638 0.7728 20190313 9dae25e forest-2 0.8269 0.8229 0.7602 0.7726 0.7656 20190313 78f2dc7 neural_clf 0.8352 0.8412 0.7723 0.7806 0.7762 20190313 14075a4 soft_max 0.8369 0.8250 0.7574 0.7911 0.7739 20190313 a592ca6 soft_max 0.8641 0.8568 0.7930 0.8000 0.7965 20190313 257fbab soft_max 0.8520 0.8474 0.7368 0.8252 0.7785 20190313 25b5456 soft_max - 0.8658 - - - 主要实验过程公共模块定义构建公共处理模块有两个目的，一是方便复用，比方说文件的保存与加载、日志的定义；二是跟实验无关的一些中间处理过程。具体代码间GitHub，主要有： config.py 定义基本配置信息，超参数设置，方便做对比实验； logger.py 日志配置，实验过程保存至日志文件； comm.py 数据的加载与保存等公共方法； 数据处理评价方法评价方法是评价一个模型好坏的准则，本次比赛测评算法指定为AUC(Area Under the Curve)，AUC值越高可以任务情感分类结果越准确。扩展资料：AUC-维基百科 | AUC-百度百科 scikit-learn 已经有AUC的封装：auc = roc_auc_score(y, y_score, average=&quot;macro&quot;) 新建 report.py 模块，定义Report类如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677class Report(): &#x27;&#x27;&#x27; 对预测结果进行评估 &#x27;&#x27;&#x27; def __init__(self, name=&#x27;&#x27;): &#x27;&#x27;&#x27; 初始化 &#x27;&#x27;&#x27; self.name = name self.f1 = [] self.p1 = [] self.r1 = [] self.f0 = [] self.p0 = [] self.r0 = [] self.auc_scores = [] self.auc = 0 def report_one_folder_by_lable(self, y, y_hat): &#x27;&#x27;&#x27; 中间结果 &#x27;&#x27;&#x27; f1_1 = metrics.f1_score(y, y_hat, pos_label=1) p_1 = metrics.precision_score(y, y_hat, pos_label=1) r_1 = metrics.recall_score(y, y_hat, pos_label=1) f1_0 = metrics.f1_score(y, y_hat, pos_label=0) p_0 = metrics.precision_score(y, y_hat, pos_label=0) r_0 = metrics.recall_score(y, y_hat, pos_label=0) self.f1.append(f1_1) self.p1.append(p_1) self.r1.append(r_1) self.f0.append(f1_0) self.p0.append(p_0) self.r0.append(r_0) logger.info(&quot;0 result p: &#123;:.4f&#125; r: &#123;:.4f&#125; f &#123;:.4f&#125;&quot;.format(p_0, r_0, f1_0)) logger.info(&quot;1 result p: &#123;:.4f&#125; r: &#123;:.4f&#125; f &#123;:.4f&#125;&quot;.format(p_1, r_1, f1_1)) return p_1 def report_one_folder(self, y, predict_proba, threshold=0.5): &#x27;&#x27;&#x27; 中间结果 &#x27;&#x27;&#x27; logger.info(self.name) y_hat = [1 if score[1] &gt;= threshold else 0 for score in predict_proba] p_1 = self.report_one_folder_by_lable(y, y_hat) # auc evaluate y_score = predict_proba[:, 1] auc = roc_auc_score(y, y_score, average=&quot;macro&quot;) self.auc_scores.append(auc) logger.info(&quot;AUC score: &#123;:.4f&#125;&quot;.format(auc)) self.auc = np.mean(self.auc_scores) return auc def report_final_result(self): &#x27;&#x27;&#x27; 最终结果 &#x27;&#x27;&#x27; logger.info(self.name) logger.info( &quot;0 avg result p: &#123;:.4f&#125; r: &#123;:.4f&#125; f &#123;:.4f&#125;&quot;.format(np.mean(self.p0), np.mean(self.r0), np.mean(self.f0))) logger.info( &quot;1 avg result p: &#123;:.4f&#125; r: &#123;:.4f&#125; f &#123;:.4f&#125;&quot;.format(np.mean(self.p1), np.mean(self.r1), np.mean(self.f1))) if len(self.auc_scores) &gt; 0: ave_auc = np.mean(self.auc_scores) logger.info( &quot;AUC avg score: &#123;:.4f&#125;&quot;.format(ave_auc)) return ave_auc return np.mean(self.p1) 特征提取新建专门的特征提取模块，命名为：feature.py,代码及解释如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import pandas as pdfrom sklearn.feature_extraction.text import TfidfVectorizerimport configimport word_vecfrom logger import loggerclass TFIDF(): &#x27;&#x27;&#x27; 提取文本的TFIDF特征 &#x27;&#x27;&#x27; def __init__(self, data, min_df=1): &#x27;&#x27;&#x27; 初始化并拟合数据集 :param data:训练集文本 &#x27;&#x27;&#x27; self.data = data logger.info(&#x27;init TfidfVectorizer&#x27;) self.tfidf = TfidfVectorizer(min_df=min_df) logger.info(&#x27;fitting Tfidf...&#x27;) self.train_vec = self.tfidf.fit_transform(data).toarray() logger.info(&#x27;end&#x27;) def transform(self, data): &#x27;&#x27;&#x27; 拟合新的数据集 :param data: 测试集文本 :return: &#x27;&#x27;&#x27; return self.tfidf.transform(data).toarray()class Feature(): &#x27;&#x27;&#x27; 特征提取的封装类 &#x27;&#x27;&#x27; def __init__(self): import comm # 加载训练集和测试集数据 self.train_data = comm.load_df(config.train_data_path) self.test_data = comm.load_df(config.test_data_path) self.test_ids = self.test_data[&quot;ID&quot;] # 测试集中所有的id self.y = self.get_target() # 训练集中的情感标签 self.train_features = [] self.test_features = [] # 提取TFIDF特征 train_vec, test_vec = self.tfidf_vec() self.train_features.append(pd.DataFrame(train_vec)) self.test_features.append(pd.DataFrame(test_vec)) # train_word_vec, test_word_vec = self.word_vec() # 加了会很低 # self.train_features.append(pd.DataFrame(train_word_vec)) # self.test_features.append(pd.DataFrame(test_word_vec)) self.X = pd.concat(self.train_features, axis=1) self.test_X = pd.concat(self.test_features, axis=1) logger.info(&quot;Shape of train X: &#123;&#125;&quot;.format(self.X.shape)) logger.info(&quot;Shape of test X: &#123;&#125;&quot;.format(self.test_X.shape)) logger.info(&quot;Shape of y: &#123;&#125;&quot;.format(self.y.shape)) def get_target(self): def get_lable(label): if label == &#x27;Positive&#x27;: return 1 # Positive 用1表示 else: return 0 # 将训练集中的标签用 0 1表示 self.train_data[&#x27;y&#x27;] = self.train_data.apply(lambda x: get_lable(x[&#x27;label&#x27;]), axis=1) return self.train_data[&#x27;y&#x27;].values.astype(&#x27;int&#x27;) def tfidf_vec(self): logger.info(&quot;start collect tfidf vec.&quot;) # 用训练集初始化TFIDF tfidf = TFIDF(self.train_data[&#x27;review&#x27;], min_df=config.tfidf_min_df) train_vec = tfidf.train_vec # 提取测试集的TFIDF特征 test_vec = tfidf.transform(self.test_data[&#x27;review&#x27;]) logger.info(&quot;shape of trian tfidf: &#123;&#125;&quot;.format(train_vec.shape)) logger.info(&quot;shape of test tfidf: &#123;&#125;&quot;.format(test_vec.shape)) return train_vec, test_vec def word_vec(self): &#x27;&#x27;&#x27; 提取文本中的词向量表示 :return: 训练集词向量，测试集词向量 &#x27;&#x27;&#x27; logger.info(&quot;word vec&quot;) train_word_vec = word_vec.get_word_vec(self.train_data[&#x27;review&#x27;]) test_word_vec = word_vec.get_word_vec(self.test_data[&#x27;review&#x27;]) logger.info(&quot;shape of trian word_vec: &#123;&#125;&quot;.format(train_word_vec.shape)) logger.info(&quot;shape of test word_vec: &#123;&#125;&quot;.format(test_word_vec.shape)) self.voc = word_vec.voc return train_word_vec, test_word_vec 训练过程新建训练模块，命名为：train.py,代码及解释如下： 分类器的定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354classfiers = &#123;&#125;features_name = []C = 1.0# classfiers[&#x27;xgb-5&#x27;] = xgb_5svm_1 = svm.SVC(C=1.0, kernel=&#x27;rbf&#x27;, gamma=&#x27;auto&#x27;, probability=True)rfc_1 = RandomForestClassifier(n_estimators=100, random_state=10)rfc_2 = RandomForestClassifier(n_estimators=200, random_state=10)rfc_3 = RandomForestClassifier(n_estimators=300, random_state=10)rfc_4 = RandomForestClassifier(n_estimators=200, max_depth=13, min_samples_split=80, min_samples_leaf=10, oob_score=True, random_state=10, max_features=&#x27;sqrt&#x27;)rfc_5 = RandomForestClassifier(random_state=30, n_estimators=30, max_depth=11, max_features=0.5, criterion=&#x27;entropy&#x27;, min_samples_split=140, min_samples_leaf=50)# Build a forest and compute the feature importancesforest_1 = ExtraTreesClassifier(n_estimators=25, random_state=0)forest_2 = ExtraTreesClassifier(n_estimators=250, random_state=0)rng = np.random.RandomState(1)bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), algorithm=&quot;SAMME&quot;, n_estimators=100)# Decision Treetree_clf = tree.DecisionTreeClassifier()# Gradient Boosting Classifiergrad_clf = GradientBoostingClassifier()# Random Forest Classifierrand_clf = RandomForestClassifier(n_estimators=18)# NeuralNet Classifierneural_clf = MLPClassifier(alpha=1)# Naives Bayesnav_clf = GaussianNB()voting_clf = VotingClassifier( estimators=[(&#x27;gbc&#x27;, grad_clf), (&#x27;nav&#x27;, nav_clf), (&#x27;neural&#x27;, neural_clf)], voting=&#x27;soft&#x27;)voting_rfc = VotingClassifier( estimators=[(&#x27;rfc&#x27;, rfc_1), (&#x27;rfc_2&#x27;, rfc_2), (&#x27;rfc_3&#x27;, rfc_3)], voting=&#x27;soft&#x27;)classfiers[&#x27;neural_clf&#x27;] = neural_clfclassfiers[&#x27;nav_clf&#x27;] = nav_clfclassfiers[&#x27;grad_clf&#x27;] = grad_clfclassfiers[&#x27;tree_clf&#x27;] = tree_clfclassfiers[&#x27;forest-1&#x27;] = forest_1classfiers[&#x27;forest-2&#x27;] = forest_2classfiers[&#x27;voting_clf&#x27;] = voting_clfclassfiers[&#x27;voting_rfc&#x27;] = voting_rfc 训练过程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859def cv(X, y, clf): &#x27;&#x27;&#x27; 交叉验证 Cross-validation :param X: 训练集特征 :param y: 目标label :param clf: 分类器 :return: 交叉验证过程中的最佳模型 &#x27;&#x27;&#x27; model = None max_p = 0 # 记录实验中最好的模型 reporter = Report(&#x27;train&#x27;) # 定义评价器 for i in range(1, 10): # 10 logger.info(&quot;Folder &#123;&#125;&quot;.format(i)) x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21 + i) if config.DEBUG: logger.info( &quot;Train x data: (&#123;&#125;, &#123;&#125;), Train y data: &#123;&#125;&quot;.format(len(x_train), len(x_train[0]), Counter(y_train))) logger.info(&quot;Test x data: (&#123;&#125;, &#123;&#125;), Test y data: &#123;&#125;&quot;.format(len(x_test), len(x_test[0]), Counter(y_test))) clf.fit(x_train, y_train) # 训练过程 predict_proba = clf.predict_proba(x_test) # 返回每个类别的概率值 # TODO 随机 看结果对比submission结果 p = reporter.report_one_folder(y_test, predict_proba, threshold=0.5) if p &gt; max_p: max_p = p logger.info(&quot;Max result: &#123;:.4f&#125;&quot;.format(p)) model = clf reporter.report_final_result() return model, reporterdef train_cv(X, y): &#x27;&#x27;&#x27; 对classfiers中的每个分类器执行 CV过程 &#x27;&#x27;&#x27; reporters = &#123;&#125; for index, (name, clf) in enumerate(classfiers.items()): logger.info(&#x27;&#123;&#125;: &#123;&#125;&#x27;.format(name, clf)) model, train_reporter = cv(X, y, clf) model_path = config.model_path + &#x27;_&#x27; + name + &quot;_&#123;:.4f&#125;&quot;.format(train_reporter.auc) comm.save_file(model, model_path) reporters[name] = [train_reporter] logger.info(&quot;Sum result:\\n&quot;) logger.info(&#x27;===========&#x27;) for name, train_reporter in reporters.items(): logger.info(&#x27;-----&#x27;) logger.info(&quot;clf: &#123;&#125;&quot;.format(name)) train_reporter[0].report_final_result()if __name__ == &quot;__main__&quot;: import comm from feature import Feature f = Feature() # 特征工程 train_cv(f.X, f.y) # 十折交叉过程 预测过程模型训练完成以后就可以使用训练好的模型预测测试文件中的情感分类，新建 predict.py ，代码和解释如下： 12345678910111213141516171819202122232425import pandas as pdimport commfrom feature import Feature# 使用的模型文件model_path = &quot;./submissions/model_neural_clf_0.8352&quot;reslut_path = model_path.replace(&#x27;model&#x27;, &#x27;reslut&#x27;).replace(&#x27;0.&#x27;, &#x27;&#x27;)reslut_path = reslut_path + &quot;.csv&quot; # 结果保存路径model = comm.load_file(model_path) # 加载模型feature = Feature()test_feature = feature.test_X # 测试文件特征ids = feature.test_ids# 预测过程，结果为两个label的概率predict_proba = model.predict_proba(test_feature)proba = predict_proba[:, 1] # 这里只取1的概率data = [] # 最终结果assert len(ids) == len(proba)for id, p in zip(ids, proba): data.append([id, p])result = pd.DataFrame(data, columns=[&#x27;ID&#x27;, &quot;Pred&quot;])comm.dump_submission(result, path=reslut_path) 全部实验项目代码见 GitHub 关键字：kesci,competition, sentiment,PyTorch 原载地址：https://www.jiancheng.ai/2019/03/15/kesci-sentiment-classification/ 转载请注明出处！","tags":[{"name":"PyTorch","slug":"PyTorch","permalink":"https://jianchengai.com/tags/PyTorch/"},{"name":"kesci","slug":"kesci","permalink":"https://jianchengai.com/tags/kesci/"},{"name":"competition","slug":"competition","permalink":"https://jianchengai.com/tags/competition/"},{"name":"sentiment","slug":"sentiment","permalink":"https://jianchengai.com/tags/sentiment/"}]},{"title":"人工智能新书推荐——《PyTorch机器学习从入门到实战》","date":"2018-11-08T02:58:54.000Z","path":"2018/11/08/pytorch-in-action-book/","text":"《PyTorch机器学习从入门到实战》内容简介近年来，基于深度学习的人工智能掀起了一股学习的热潮。本书是使用PyTorch深度学习框架的入门书籍。本书从深度学习原理入手，由浅入深，阐述深度学习中神经网络、深度神经网络、卷积神经网络、自编码器、循环神经网络等，同时穿插学习PyTorch框架的各个知识点和基于知识点的实例。最后，综合运用PyTorch和深度学习知识，来解决实践中的具体问题，比如图像识别、文本分类和命令词识别等。可以说，本书是深度学习和PyTorch的入门教程，同时也引领读者登堂入室，进入机会和挑战的人工智能领域。 本书针对的对象是机器学习和人工智能的爱好者和研究者，希望其能够有一定的机器学习和深度学习知识，有一定的Python编程基础。 购书链接：机械工业出版社 | 亚马逊 | china-pub | 当当 | 京东 书籍代码地址：https://github.com/xiaobaoonline/pytorch-in-action 目录12345678910111213141516171819202122232425262728293031323334353637383940414243第 1 章 深度学习介绍 1.1 人工智能、机器学习与深度学习 1.2 深度学习工具介绍 1.3 PyTorch 介绍 1.4 你能从本书中学到什么第 2 章 PyTorch 安装和快速上手 2.1 PyTorch 安装 2.2 Jupyter Notebook 使用 2.3 NumPy 基础知识 2.4 PyTorch 基础知识第 3 章 神经网络 3.1 神经元与神经网络 3.2 激活函数 3.3 前向算法 3.4 损失函数 3.5 反向传播算法 3.6 数据的准备 3.7 PyTorch 实例：单层神经网络实现第 4 章 深度神经网络及训练 4.1 深度神经网络 4.2 梯度下降 4.3 优化器 4.4 正则化 4.5 PyTorch 实例：深度神经网络实现第 5 章 卷积神经网络 5.1 计算机视觉 5.2 卷积神经网络 5.3 MNIST 数据集上卷积神经网络的实现第 6 章 嵌入与表征学习 6.1 PCA 6.2 自编码器 6.3 词嵌入第 7 章 序列预测模型 7.1 序列数据处理 7.2 循环神经网络 7.3 LSTM 和 GRU 7.4 LSTM 在自然语言处理中的应用 7.5 序列到序列网络 7.6 PyTorch 实例：基于 GRU 和 Attention 的机器翻译第 8 章 PyTorch 项目实战 8.1 图像识别和迁移学习——猫狗大战 8.2 文本分类 8.3 语音识别系统介绍 关键字：人工智能, PyTorch 原载地址：https://blog.csdn.net/jianchengss/article/details/83744500 转载请注明出处！","tags":[{"name":"PyTorch","slug":"PyTorch","permalink":"https://jianchengai.com/tags/PyTorch/"},{"name":"人工智能","slug":"人工智能","permalink":"https://jianchengai.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}]},{"title":"Markdown中的变量引用","date":"2018-04-05T10:34:06.000Z","path":"2018/04/05/Markdown中的变量引用/","text":"写东西的时候突发奇想，Markdown支持变量引用吗？这么高大上的工具应该支持的吧？！于是就查阅了一些资料:果然支持！ 下面把变量引用的用法记录一下。使用变量的好处，应该是很明显的：一处定义，处处使用，而且方便统一修改。 示例中二维码是我刚开通个人公众号，有兴趣的关注一波啊，应该是很安静的～ O(∩_∩)O 变量定义格式，支持中文 :-) 1234[baidu]:http://www.baidu.com[我的主页]:http://www.jiancheng.ai[image-qr-code]: https://gitee.com/jianchengss/resources/raw/master/images/weixin/mp_QR-code/Jason_pinyaxuan_8.jpg[image-error]: https://www.baidu.com/Jason_pinyaxuan_8.jpg 定义的变量可以在文档的任何位置，而且在正文中不显示，比如说本文底部定义了上面代码块里的变量，供下面示例使用，不过页面上是看不到的。 注意！链接写的时候一定要带 http://,不然链接不生效，不要问我是怎么知道的！！ 变量使用12345678910### 示例1直接把key放入[],这样显示文本是key，链接为value（但是两个放在一行会出问题，而且要空一行才能正确显示两个。。。。）:[baidu] [我的主页] ← 这里有两，只会显示第一个，估计识别成两个中括号的模式了（因为鼠标放上去显示链接是第二个变量值，两个中括号中间空格无效）[baidu][我的主页] 示例1直接把key放入[],这样显示文本是key，链接为value（但是两个放在一行会出问题，而且要空一行才能正确显示两个。。。。）: baidu 我的主页 ← 这里有两，只会显示第一个，估计识别成两个中括号的模式了（因为鼠标放上去显示链接是第二个变量值，两个中括号中间空格无效） baidu 我的主页 12345### 示例2自定义链接显示文本 + key，分别在[]里：[百度][baidu] [我的主页][我的主页] 示例2自定义链接显示文本 + key，分别在[]里： 百度 我的主页 12345678### 示例3图片中引用变量：直接使用，前面加感叹号，这样图片失效的时候显示的是key，图片显示是value指向的图片：![image-qr-code]![image-error] 示例3图片中引用变量： 直接使用，前面加感叹号，这样图片失效的时候显示的是key，图片显示是value指向的图片： 1234567### 示例4感叹号+[图片失效是显示文本] + [key], 自定义图片失效是显文本:![图片失效是显示文本][image-qr-code]![图片加载失败][image-error] 示例4感叹号+[图片失效时显示文本] + [key], 自定义图片失效是显文本: 关键字：Markdown, 变量引用 原载地址：http://www.jiancheng.ai/2018/04/05/Markdown中的变量引用/ 转载请注明出处！","tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://jianchengai.com/tags/Markdown/"}]},{"title":"机器学习资源汇总","date":"2018-02-11T12:04:16.000Z","path":"2018/02/11/机器学习资源汇总/","text":":page.sourse平时看到的机器学习相关资源汇总到这里，好记性不如烂笔头！ 论文 学界 | 2010-2016年被引用次数最多的深度学习论文（附论文下载） 微软重磅论文提出LightRNN：高效利用内存和计算的循环神经网络 100 Must-Read NLProc Papers 深度学习论文阅读路线图 Deep Learning Papers Reading Roadmap 论文《Provable Algorithms for Machine Learning Problems》,机器学习若干问题的新颖，可证明，实用算法 “Provable Algorithms for Machine Learning Problems”, [Rong Ge, 2013] 涉及三大类：主题模型，稀疏、深度表示，隐变量模型、张量分解&#x2F;矩阵分解，PS: NIPS’16最佳学生论文合作者(Provable Algorithms for Machine Learning Problems.pdf) 【论文】（论文+代码）加速的PixelCNN ++，图像生成效率提升了183倍(FAST GENERATION FOR CONVOLUTIONAL AUTORGRESSIVE MODELS) 机器学习和深度学习引用量最高的20篇论文（2014-2017） 面向推荐系统的深度学习文献列表 总结 机器学习入门资源不完全汇总 机器学习水平自测40题(附答案&amp;解析) Solutions for Skilltest Machine Learning : Revealed 网站 &amp;论坛 机器学习日报 机器学习：CSDN知识库 博客：计算机的潜意识 机器学习基本方法 机器学习所需的数学基础 【技术干货】Docker精华学习资料集锦 西瓜书 机器学习(周志华西瓜书) 参考答案 总目录 深度学习中文版 来自liip师兄的分享 神经网络演示 http://playground.tensorflow.org/ 知乎专栏：智能单元 聚焦通用人工智能 反向传播算法入门资源索引 Java方向技术面试答案(汇总版) Python Python 资源大全 用一个实际的数据集练手pandas Top 10 IPython Notebook 谷歌开源项目风格指南之 Python 风格指南 我理解的python最佳实践 Transfer Learning Applying transfer learning in NLP and CV https://towardsdatascience.com/applying-transfer-learning-in-nlp-and-cv-d4aaddd7ca90 java Java8-CheatSheet Java 8 Tutorials, Resources, Books and Examples to learn Lambdas, Stream API and Functional Interfaces 博 文 机器学习入门 ——奇迹不是因果的积累，而是宿命的选择 SVM 支持向量机通俗导论（理解SVM的三层境界） What is the class of this image 各种数据集上的数字识别汇总 知乎：深度学习有哪些好玩的且易于实现的论文？ 文本挖掘预处理的流程总结 这10本由浅入深的好书，或让你成为机器学习领域的专家 每天一个 Linux 命令：系列目录 独立开发者赚钱资料集锦 各种相似度介绍、 Python实现《统计学习方法》中的所有十个算法， 深度学习入门系列 机器学习新手必学十大算法指南 课程 吴立德 《深度学习课程》 卷积神经网络： 卷积核可视化 斯坦福大学的课程 :cs231n https://github.com/cs231n/cs231n.github.io http://cs231n.github.io/ CS 294：深度增强学习，2017年春季学期 &amp;&amp; 【Berkeley CS 294：深度增强学习，2017年春季学期】学习资源（附字幕） 已转存 李宏毅 台大李宏毅中文深度学习课程(2017) 本地资源DataSet THE MNIST DATABASE Face Recognition:The ORL dataset (Samaria F, Harter A (1994) Parameterisation of a stochastic model for human face identification, Proceedings of 2nd IEEE Workshop on Applications of Computer Vision.) Music Classification:The GTZAN dataset: Musical genre classification of audio signals Hand Movement Recognition -The sEMG dataset Improving EMG based classificationof basic hand movements using EMD UC Irvine Machine Learning Repository 双语平行语料：Tab-delimited Bilingual Sentence Pairs 关键字：机器学习, 资源列表 原载地址：http://www.jiancheng.ai/2018/02/11/机器学习资源汇总/ 转载请注明出处！","tags":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"https://jianchengai.com/tags/MachineLearning/"}]},{"title":"Docker:使用jupyter notebook基础镜像搭建自己的PyTorch开发环境","date":"2018-02-11T11:52:31.000Z","path":"2018/02/11/Docker-使用jupyter-notebook基础镜像搭建自己的PyTorch开发环境/","text":"使用Docker搭建自己的PyTorch开发环境，方便迁移和远程使用。 启动最基本的jupyter notebook镜像：使用基础镜像jupyter&#x2F;datascience-notebook,因为它预装了常用的模块：pandas, matplotlib, scipy, seaborn, scikit-learn, scikit-image, sympy, cython, patsy, statsmodel, cloudpickle, dill, numba, bokeh； 1docker run -it --rm -p 8888:8888 jupyter/datascience-notebook:281505737f8a 其中docker run 是使用一个镜像生成一个运行的容器； -it指交互模式，启动后终端在运行着的容器里面，与之对应的有-d后端运行模式，启动后终端交互在实体机，要想进入容器需要使用命令docker exec -it container-name bash docker exec -it container-name意为交互模式进入正在运行的一个容器，bash意为进入容器后使用的命令，这里用的是bash，这样进入容器后就能执行shell； --rm意为退出shell的时候自动删除容器，常在测试的时候使用，这样不用每次修改去删除已有的容器； -p 8888:8888指的是端口映射，前面的是实体机的端口，后面是容器里面暴露出的端口，两边端口可以不一样，这样同一个镜像可以启动多个对应不同端口的服务； jupyter/datascience-notebook:281505737f8a是镜像名字，冒号后面的是tag，类似于版本的概念，如果不显式的给出tag每次都回从hub上拉取latest的镜像，如果网络环境不好的话比较费时间，推荐显式给出tag，这样每次构建都会使用已有的镜像。 启动后就可以在终端看到： 123456789101112[I 04:01:05.691 NotebookApp] Running the core application with no additional extensions or settings[I 04:01:05.692 NotebookApp] Serving notebooks from local directory: /home/jovyan[I 04:01:05.692 NotebookApp] 0 active kernels[I 04:01:05.692 NotebookApp] The Jupyter Notebook is running at:[I 04:01:05.692 NotebookApp] http://[all ip addresses on your system]:8888/?token=0a3331628e0e35f94eb0ad543faeb3e396fbccfa3ff06e5a[I 04:01:05.692 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 04:01:05.692 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=0a3331628e0e35f94eb0ad543faeb3e396fbccfa3ff06e5a 此时是停在容器里面，打开浏览器 访问http://localhost:8888/?token=0a3331628e0e35f94eb0ad543faeb3e396fbccfa3ff06e5a 即可打开基本的jupyter notebook 环境，后面的token是随机生成的； 启动带权限的容器生成自定义token123# Python脚本生成密码import IPythonIPython.lib.passwd() 输入密码生成token 1test的token：sha1:6587feaef3b1:6b243404e4cfaafe611fdf494ee71fdaa8c4a563 自定义token运行容器：1docker run -d -p 8888:8888 jupyter/datascience-notebook start-notebook.sh --NotebookApp.password=&#x27;sha1:6587feaef3b1:6b243404e4cfaafe611fdf494ee71fdaa8c4a563&#x27; 这时访问http://localhost:8888/会出现输入密码的页面，输入正确的密码才能进入jupyter。 共享目录-v参数docker提供-v参数使实体机和容器共享目录，这对于有状态的服务很有用，目录挂载添加参数：-v /home/jason/jason/docker/notebook:/home/jovyan/work 运行带有目录共享的容器1docker run -it --rm -p 8888:8888 -v /home/jason/jason/docker/notebook:/home/jovyan/work jupyter/datascience-notebook start-notebook.sh --NotebookApp.password=&#x27;sha1:6587feaef3b1:6b243404e4cfaafe611fdf494ee71fdaa8c4a563&#x27; 这样在jupyter里新建的notebook都会出现在实体机指定的目录里。由于这个镜像的原因 需在work目录下新建才能在实体机看到。 基于jupyter&#x2F;datascience-notebook 生成pytorch imageDockerfile因为没有合适的pytorch镜像，自己编辑Dockerfile: 新建文件Dockerfile并编辑内容： 12345678910FROM jupyter/datascience-notebook:281505737f8aMAINTAINER Jason.W. &quot;jianchengss@163.com&quot;# 下面是按官网的方法安装spotlight#RUN pip --no-cache-dir install --upgrade install http://download.pytorch.org/whl/cu75/torch-0.2.0.post3-cp36-cp36m-manylinux1_x86_64.whl #RUN pip --no-cache-dir install --upgrade torchvision# pytorchRUN conda install pytorch torchvision -c soumith# spotlight(https://github.com/maciejkula/spotlight)RUN conda install -c maciejkula -c soumith spotlight=0.1.2 build在Dockerfile目录里运行命令：docker build -t jianchengss/datascience-pytorch:0.1 .这样就生成了image：jianchengss/datascience-pytorch:0.1可以运行docker images查看本机上所有的image。 从构建的镜像运行容器1docker run -it --rm -p 8888:8888 -v ~/workspace/python/notebooks-pytorch:/home/jovyan/work --privileged=true jianchengss/datascience-pytorch:0.1 start-notebook.sh --NotebookApp.password=&#x27;sha1:6587feaef3b1:6b243404e4cfaafe611fdf494ee71fdaa8c4a563&#x27; 最终容器经过以上步骤，测试完成后既可以执行最终运行的命令 注意 token换成自己的 12docker run -d -p 8588:8888 -v ~/workspace/python/notebooks-pytorch:/home/jovyan/work --privileged=true --name=pytorch jianchengss/datascience-pytorch:0.1 start-notebook.sh --NotebookApp.password=&#x27;sha1:7aee2f913c8e:17d40f203cbd5c9820f302894a92724c3de9fba6&#x27; -it --rm 换成了 -d,比之前多的参数有： --name=pytorch，意为给container取一个名字，好区分和管理，缺省的话名字为一串随机的字符串。 --privileged=true出现文件夹访问权限的时候添加该属性 此时运行docker ps即可查看运行着的容器： 123CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3bd3e30e9ab3 jianchengss/datascience-pytorch:0.1 &quot;tini -- start-notebo&quot; 4 seconds ago Up 3 seconds 0.0.0.0:8588-&gt;8888/tcp pytorch 进入容器操作容器启动后有时候需要进入容器操作，比方说查看信息或者安装新的软件，此时执行docker exec -it pytorch bash 其他命令123docker stop container-name # 停止运行着的容器docker rm container-name # 删除已有的容器，要先停止docker rmi image-name # 删除已有的镜像 关键字：docker jupyter notebook pytorch spotlight 原载地址：http://www.jiancheng.ai/2018/02/11/Docker-使用jupyter-notebook基础镜像搭建自己的PyTorch开发环境/ 转载请注明出处！","tags":[{"name":"Docker","slug":"Docker","permalink":"https://jianchengai.com/tags/Docker/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://jianchengai.com/tags/PyTorch/"}]}]